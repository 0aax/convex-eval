\subsection{Image of a function under a linear mapping}

\begin{theorem}\label{thm:2.1.1}
With the above notation, assume that $\operatorname{Im}A^* \cap \dom g^* \neq\varnothing$. Then $Ag$ satisfies (1.1.1) and its conjugate is
\[
(Ag)^* = g^* \circ A^* .
\]
\end{theorem}

\begin{proof}
First, it is clear that $Ag \not\equiv +\infty$ (take $x=Ay$, with $y\in\dom g$). On the other hand, our assumption implies the existence of some $p_0 = A^*s_0$ such that $g^*(p_0)<+\infty$; with Fenchel's inequality (1.1.3), we have for all $y\in\mathbb R^m$:
\[
g(y) \ge \langle A^*s_0,y\rangle_m - g^*(p_0) = \langle s_0,Ay\rangle_n - g^*(p_0).
\]
For each $x\in\mathbb R^n$, take the infimum over those $y$ satisfying $Ay=x$: the affine function $\langle s_0,\cdot\rangle - g^*(p_0)$ minorizes $Ag$. Altogether, $Ag$ satisfies (1.1.1).

Then we have for $s\in\mathbb R^n$
\[
(Ag)^*(s) = \sup_{x\in\mathbb R^n}[\langle s,x\rangle - \inf_{Ay=x} g(y)]
= \sup_{x\in\mathbb R^n,\,Ay=x}[\langle s,x\rangle - g(y)]
= \sup_{y\in\mathbb R^m}[\langle s,Ay\rangle - g(y)] = g^*(A^*s).
\]
\end{proof}

\begin{corollary}
\label{cor:2.1.2}
With $g:\mathbb{R}^n\times\mathbb{R}^p=\mathbb{R}^m\to\mathbb{R}\cup\{+\infty\}$ not identically $+\infty$, let $g^*$ be associated with a scalar product preserving the structure of $\mathbb{R}^m$ as a product space: $\langle\cdot,\cdot\rangle_m=\langle\cdot,\cdot\rangle_n+\langle\cdot,\cdot\rangle_p$. If there exists $s_0\in\mathbb{R}^n$ such that $(s_0,0)\in\operatorname{dom} g^*$, then the conjugate of $f$ defined by (2.1.2) is
\[
f^*(s)=g^*(s,0)\qquad\text{for all }s\in\mathbb{R}^n.
\]
\end{corollary}

\begin{proof}
It suffices to observe that, $A$ being the projection defined above, there holds for all $y_1=(x_1,z_1)\in\mathbb{R}^{m}$ and $x_2\in\mathbb{R}^n$,
\[
\langle Ay_1,x_2\rangle_n=\langle x_1,x_2\rangle_n=\langle x_1,x_2\rangle_n+\langle z_1,0\rangle_p=\langle y_1,(x_2,0)\rangle_m,
\]
which defines the adjoint $A^*x=(x,0)$ for all $x\in\mathbb{R}^n$. Then apply Theorem 2.1.1.
\end{proof}

\begin{corollary}\label{cor:2.1.3}
Let $f_1$ and $f_2$ be two functions from $\mathbb{R}^n$ to $\mathbb{R}\cup\{+\infty\}$, not identically $+\infty$, and satisfying $\operatorname{dom} f_1^*\cap\operatorname{dom} f_2^*\neq\varnothing$. Then their inf-convolution satisfies (1.1.1), and $(f_1\infconv f_2)^*=f_1^*+f_2^*$.
\end{corollary}

\begin{proof}
Equip $\mathbb{R}^n\times\mathbb{R}^n$ with the scalar product $\langle\cdot,\cdot\rangle+\langle\cdot,\cdot\rangle$. Using the above notation for $g$ and $A$, we have $g^*(s_1,s_2)=f_1^*(s_1)+f_2^*(s_2)$ (Proposition 1.3.1(ix)) and $A^*(s)=(s,s)$. Then apply the definitions.
\end{proof}

\subsection{Pre-composition with an affine mapping}

\begin{theorem}\label{thm:2.2.1}
Take $g\in\Conv\mathbb{R}^m$, $A_0$ linear from $\mathbb{R}^n$ to $\mathbb{R}^m$ and consider the affine operator $A(x):=A_0x+y_0\in\mathbb{R}^m$. Suppose that $A(\mathbb{R}^n)\cap\dom g\neq\emptyset$. Then
$g\circ A\in\Conv\mathbb{R}^n$ and its conjugate is the closure of the convex function
\[
\mathbb{R}^n\ni s\mapsto\inf_p\{\,g^*(p)-\langle y_0,p\rangle_m : A_0^*p=s\,\}.
\tag{2.2.1}
\]
\end{theorem}

\begin{proof}
We start with the linear case ($y_0=0$): suppose that $h\in\Conv\mathbb{R}^n$ satisfies $\Im A_0\cap\dom h\neq\emptyset$. Then Theorem 2.1.1 applied to $g:=h^*$ and $A:=A_0^*$ gives $(A_0^*h^*)^*=h\circ A_0$; conjugating both sides, we see that the conjugate of $h\circ A_0$ is the closure of the image-function $A_0^*h^*$.

In the affine case, consider the function $h:=g(\cdot+y_0)\in\Conv\mathbb{R}^m$; its conjugate is given by Proposition 1.3.1(v): $h^*=g^*-\langle y_0,\cdot\rangle_m$. Furthermore, it is clear that
\[
(g\circ A)(x)=g(A_0x+y_0)=h(A_0x)=(h\circ A_0)(x),
\]
so (2.2.1) follows from the linear case.
\end{proof}

\begin{lemma}
Let $g\in\operatorname{Conv}\mathbb{R}^m$ be such that $0\in\dom g$ and let $A_0$ be linear from $\mathbb{R}^n$ to $\mathbb{R}^m$. Make the following assumption:

\[
\Im A_0\cap\ri\dom g\neq\emptyset\quad\text{i.e.}\quad
0\in\ri\dom g-\Im A_0\ [=\ri(\dom g-\Im A_0)].
\]

Then $(g\circ A_0)^* = A_0^* g^*$; for every $s\in\dom (g\circ A_0)^*$, the problem
\begin{equation}\label{eq:2.2.2}
\inf_{p}\{\,g^*(p):\ A_0^*p=s\,\}
\end{equation}
has at least one optimal solution $\bar p$ and there holds $(g\circ A_0)^*(s)=A_0^*g^*(s)=g^*(\bar p)$.
\end{lemma}

\begin{proof}
To prove $(g\circ A_0)^* = A_0^* g^*$, we have to prove that $A_0^* g^*$ is a closed function, i.e.\ that its sublevel-sets are closed (Definition B.1.2.3).

Thus, for given $r\in\mathbb{R}$, take a sequence $(s_k)$ converging to some $s$ and such that
\[
(A_0^* g^*)(s_k) \le r.
\]
Take also $\delta_k\downarrow 0$; from the definition of the image-function, we can find $p_k\in\mathbb{R}^m$ such that
\[
g^*(p_k) \le r + \delta_k\quad\text{and}\quad A_0^* p_k = s_k.
\]

Let $q_k$ be the orthogonal projection of $p_k$ onto the subspace $V := \operatorname{lin}\dom g - \Im A_0$. Since $V$ contains $\operatorname{lin}\dom g$, Proposition 1.3.4 (with $z=0$) gives $g^*(p_k) = g^*(q_k)$. Furthermore, $V^\perp = (\lin\dom g)^\perp \cap \Ker A_0^*$; in particular, $q_k - p_k \in \Ker A_0^*$. In summary, we have singled out $q_k\in V$ such that
\[
g^*(q_k) \le r + \delta_k\quad\text{and}\quad A_0^* q_k = s_k\qquad\text{for all }k.
\tag{2.2.3}
\]

Suppose we can bound $q_k$. Extracting a subsequence if necessary, we will have $q_k \to \bar q$ and, passing to the limit, we will obtain (since $g^*$ is l.s.c)
\[
g^*(\bar q) \le \liminf g^*(q_k) \le r\quad\text{and}\quad A_0^* \bar q = s.
\]

The required closedness property $A_0^* g^*(\bar q) \le r$ will follow by definition. Furthermore, this $\bar q$ will be a solution of (2.2.2) in the particular case $s_k \equiv s$ and $r = (A_0^* g^*)(s)$. In this case, $(q_k)$ will be actually a minimizing sequence of (2.2.2).

To prove boundedness of $q_k$, use the assumption: for some $\varepsilon>0$, $B_m(0,\varepsilon)\cap V$ is included in $\dom g - \Im A$. Thus, for arbitrary $z\in B_m(0,\varepsilon)\cap V$, we can find $y\in\dom g$ and $x\in\mathbb{R}^n$ such that $z = y - A_0 x$. Then
\begin{align*}
\langle q_k, z\rangle_m &= \langle q_k, y\rangle_m - \langle A_0^* q_k, x\rangle_n\\
&\le g(y) + g^*(q_k) - \langle A_0^* q_k, x\rangle_n &&[\text{Fenchel (1.1.3)}]\\
&\le g(y) + r + \delta_k - \langle s_k, x\rangle_n. &&[(2.2.3)]
\end{align*}

We conclude that $\sup\{\langle q_k, z\rangle : k=1,2,\dots\}$ is bounded for any $z\in B_m(0,\varepsilon)\cap V$, which implies that $q_k$ is bounded; this is Proposition V.2.1.3 in the vector space $V$.
\end{proof}

\begin{theorem}\label{thm:2.2.3}
Take $g\in\operatorname{Conv}\mathbb{R}^m$, $A_0$ linear from $\mathbb{R}^n$ to $\mathbb{R}^m$ and consider the affine operator $A(x):=A_0x+y_0\in\mathbb{R}^m$. Make the following assumption:
\[
A(\mathbb{R}^n)\cap\operatorname{ri}\operatorname{dom}g\neq\varnothing.
\tag{2.2.4}
\]
Then, for every $s\in\operatorname{dom}(g\circ A_0)^*$, the problem
\[
\min_p\{\,g^*(p)-\langle p,y_0\rangle :\ A_0^*p=s\,\}
\tag{2.2.5}
\]
has at least one optimal solution $\bar p$ and there holds $(g\circ A)^*(s)=g^*(\bar p)-\langle\bar p,y_0\rangle$.
\end{theorem}

\begin{proof}
By assumption, we can choose $\bar x \in \mathbb{R}^n$ such that $\bar y := A(\bar x)\in\operatorname{ri}\operatorname{dom} g$. Consider the function $\bar g:=g(\bar y+\cdot)\in\operatorname{Conv}\mathbb{R}^m$. Observing that
\[
(g\circ A)(x)=\bar g(A(x)-\bar y)=(\bar g\circ A_0)(x-\bar x),
\]
we obtain from the calculus rule 1.3.1(v): $(g\circ A)^*=(\bar g\circ A_0)^*+\langle\cdot,\bar x\rangle$.

Then Lemma 2.2.2 allows the computation of this conjugate. We have $0$ in the domain of $\bar g$, and even in its relative interior:
\[
\operatorname{ri}\operatorname{dom}\bar g=\operatorname{ri}\operatorname{dom} g-\{\bar y\}\ni 0\in\operatorname{Im}A_0.
\]
We can therefore write: for all $s\in\operatorname{dom}(\bar g\circ A_0)^* [=\operatorname{dom}(g\circ A)^*]$,
\[
(\bar g\circ A_0)^*(s)=\min_{p}\{\bar g^*(p)\;:\;A_0^*p=s\},
\]
where the minimum is attained at some $\bar p$. Using again the calculus rule 1.3.1(v) and various relations from above, we have established
\[
(g\circ A)^*(s)-\langle s,\bar x\rangle=\min\{\bar g^*(p)-\langle p,A_0\bar x+y_0\rangle:\;A_0^*p=s\}
\]
\[
=\min\{g^*(p)-\langle p,y_0\rangle:\;A_0^*p=s\}-\langle s,\bar x\rangle.
\]
\end{proof}

\subsection{Sum of two functions}

\begin{theorem}\label{thm:2.3.1}
Let $g_1,g_2$ be in $\operatorname{Conv}\mathbb{R}^n$ and assume that $\operatorname{dom}g_1\cap\operatorname{dom}g_2\neq\varnothing$. The conjugate $(g_1+g_2)^*$ of their sum is the closure of the convex function $g_1^*\infconv g_2^*$.
\end{theorem}

\begin{proof}
Call $f_i^*:=g_i$, for $i=1,2$; apply Corollary 2.1.3: $(g_1^*\infconv g_2^*)^*=g_1+g_2$; then take the conjugate again.
\end{proof}

\begin{theorem}\label{thm:2.3.2}
Let $g_1,g_2$ be in $\Conv\R^n$ and assume that
\[
\begin{aligned}
&\text{the relative interiors of }\dom g_1\text{ and }\dom g_2\text{ intersect,}\\
&\text{or equivalently: }0\in\ri(\dom g_1-\dom g_2).
\end{aligned}
\tag{2.3.1}
\]
Then $(g_1+g_2)^* = g_1^*\infconv g_2^*$ and, for every $s\in\dom (g_1+g_2)^*$, the problem
\[
\inf\{g_1^*(p)+g_2^*(q)\;:\;p+q=s\}
\]
has at least one optimal solution $(\bar p,\bar q)$, which therefore satisfies
\[
g_1^*(\bar p)+g_2^*(\bar q)=(g_1^*\infconv g_2^*)(s)=(g_1+g_2)^*(s).
\]
\end{theorem}

\begin{proof}
Define $g\in\Conv(\R^n\times\R^n)$ by $g(x_1,x_2):=g_1(x_1)+g_2(x_2)$ and the linear operator $A:\R^n\to\R^n\times\R^n$ by $Ax:=(x,x)$. Then $g\circ A=g_1+g_2$, and we proceed to use Theorem 2.2.3. As seen in Proposition 1.3.1(ix), $g^*(p,q)=g_1^*(p)+g_2^*(q)$ and straightforward calculation shows that $A^*(p,q)=p+q$. Thus, if we can apply Theorem 2.2.3, we can write
\[
(g_1+g_2)^*(s)=(g\circ A)^*(s)=(A^*g^*)(s)
=\inf_{p,q}\{g_1^*(p)+g_2^*(q)\;:\;p+q=s\}=(g_1^*\infconv g_2^*)(s)
\]
and the above minimization problem does have an optimal solution.
\end{proof}

To check (2.2.4), note that $\dom g=\dom g_1\times\dom g_2$, and $\Im A$ is the diagonal set $\Delta:=\{(s,s):s\in\Bbb R^n\}$. We have
\[
(x,x)\in\ri\dom g_1\times\ri\dom g_2=\ri(\dom g_1\times\dom g_2)
\]
(Proposition A.2.1.11), and this just means that $\Im A=\Delta$ has a nonempty intersection with $\ri\dom g$.

Corollary 2.3.3 Take $f_1$ and $f_2$ in $\operatorname{Conv}\mathbb{R}^n$, with $f_1$ $0$-coercive and $f_2$ bounded from below. Then the inf-convolution problem (2.1.3) has a nonempty compact set of solutions; furthermore $f_1\infconv f_2\in\operatorname{Conv}\mathbb{R}^n$.

\begin{proof}
Letting $\mu$ denote a lower bound for $f_2$, we have $f_1(x_1)+f_2(x-x_1)\ge f_1(x_1)+\mu$ for all $x_1\in\mathbb{R}^n$, and the first part of the claim follows.

For closedness of the infimal convolution, we set $g_i:=f_i^*$, $i=1,2$; because of $0$-coercivity of $f_1$, $0\in\operatorname{int}\dom g_1$ (Remark 1.3.10), and $g_2(0)\le -\mu$. Thus, we can apply Theorem 2.3.2 with the qualification assumption (2.3.Q.ij').
\end{proof}

\subsection{Infima and suprema}

\begin{theorem}\label{thm:2.4.1}
Let $\{f_j\}_{j\in J}$ be a collection of functions satisfying (1.1.1) and having a common affine minorant: $\sup_{j\in J} f_j^*(s) < +\infty$ for some $s\in\mathbb{R}^n$.
Then their infimum $f := \inf_{j\in J} f_j$ satisfies (1.1.1), and its conjugate is the supremum of the $f_j^*$'s:
\[
(\inf_{j\in J} f_j)^* = \sup_{j\in J} f_j^*.
\tag{2.4.1}
\]
\end{theorem}

\begin{proof}
By definition, for all $s\in\mathbb{R}^n$
\[
\begin{aligned}
f^*(s)
&= \sup_x\big[\langle s,x\rangle - \inf_{j\in J} f_j(x)\big] \\
&= \sup_x \sup_j\big[\langle s,x\rangle - f_j(x)\big] \\
&= \sup_j \sup_x\big[\langle s,x\rangle - f_j(x)\big] = \sup_{j\in J} f_j^*(s).
\end{aligned}
\]
\end{proof}

\begin{theorem}\label{thm:2.4.4}
Let $\{g_j\}_{j\in J}$ be a collection of functions in \(\Conv\mathbb{R}^n\).  If their supremum \(g:=\sup_{j\in J} g_j\) is not identically \(+\infty\), it is in \(\Conv\mathbb{R}^n\), and its conjugate is the closed convex hull of the \(g_j^*\)'s:
\[
\bigl(\sup_{j\in J} g_j\bigr)^* = \overline{\co}\bigl(\inf_{j\in J} g_j^*\bigr).
\tag{2.4.5}
\]
\end{theorem}

\begin{proof}
Call \(f_j:=g_j^*\), hence \(f_j^*=g_j\), and \(g\) is nothing but the \(f^*\) of (2.4.1).  Taking the conjugate of both sides, the result follows from (1.3.4).
\end{proof}

\subsection{Post-composition with an increasing convex function}

\begin{theorem}\label{thm:2.5.1}
With $f$ and $g$ defined as above, assume that $f(\mathbb R^n)\cap\operatorname{int}\operatorname{dom}g\neq\varnothing$. For all $s\in\operatorname{dom}(g\circ f)^*$, define the function $\psi_s\in\operatorname{Conv}\mathbb R$ by
\[
\mathbb R\ni\alpha\mapsto\psi_s(\alpha):=
\begin{cases}
\alpha f^*\!\big(\tfrac{1}{\alpha}s\big)+g^*(\alpha)&\text{if }\alpha>0,\\[4pt]
\sigma_{\operatorname{dom}f}(s)+g^*(0)&\text{if }\alpha=0,\\[4pt]
+\infty&\text{if }\alpha<0.
\end{cases}
\]
Then $(g\circ f)^*(s)=\min_{\alpha\in\mathbb R}\psi_s(\alpha)$.
\end{theorem}

\begin{proof}
By definition,
\[
-(g\circ f)^*(s)=\inf_x[g(f(x))-\langle s,x\rangle]
=\inf_{x,r}\{g(r)-\langle s,x\rangle:\;f(x)\le r\}
=\inf_{x,r}[g(r)-\langle s,x\rangle+\iota_{\operatorname{epi}f}(x,r)].
\]
[ $g$ is increasing]

We must compute the conjugate of the sum of the two functions $f_1(x,r):=g(r)-\langle s,x\rangle$ and $f_2:=\iota_{\operatorname{epi}f}$, at the obvious argument $(x,r)\in\mathbb R^n\times\mathbb R$. We have $\operatorname{dom}f_1=\mathbb R^n\times\operatorname{dom}g$, so that $\operatorname{dom}f_1=\mathbb R^n\times\operatorname{dom}g$; hence, by assumption:
\[
\operatorname{int}\operatorname{dom}f_1\cap\operatorname{dom}f_2=(\mathbb R^n\times\operatorname{int}\operatorname{dom}g)\cap\operatorname{epi}f\neq\varnothing.
\]

Theorem 2.3.2, more precisely Fenchel's duality theorem (2.3.2), can be applied with the qualification condition (2.3.Q.jj'):
\[
(g\circ f)^*(s)=\min\{f_1^*(-p,\alpha)+f_2^*(p,-\alpha):\;(p,\alpha)\in\mathbb R^n\times\mathbb R\}.
\]

The computation of the above two conjugates is straightforward and gives
\[
(g\circ f)^*(s)=\min_{p,\alpha}\big[g^*(\alpha)+\iota_{\{-s\}}(-p)+\sigma_{\operatorname{epi}f}(p,-\alpha)\big]
=\min_{\alpha}\psi_s(\alpha),
\]
where the second equality comes from (1.2.2).
\end{proof}